%================================================================
\section{Protocol}\label{sec:protocol}
%================================================================
\begin{description}
    \item[29.02.24] Decided on main article to base the project on \cite{sorscher:2023:unified_theory} with support from \cite{banino:2018:vector_based}. Set up a conda environment for the project, which included \verb|PyTorch| and \verb|RatInABox| \cite{george:2022:ratinabox}. Produced a test trajectory, found out how to export the velocity and position data and convert to tensor. Started the implementation of vanilla RNN class.
    
    To do:
    \begin{enumerate}
        \item Read the chapter on RNN in GBC.
        \item Need to figure out how to generate multiple trajectories and build a multi-dimensional tensor.
        \item Also, how to take the velocity data as input in batches of sequences. 
    \end{enumerate}

    \item[01.03.24] Went over a general setup of RNNs using \verb|PyTorch|, and set up a vanilla RNN. Howerver, I'm having issues with the dimensions of the data and the layers so it is not working. Read chapter 10.1-10.6 and 10.12 in GBC \cite{gbc:2016:deep_learning} about RNNs.

    To do:
    \begin{enumerate}
        \item Read chapter 10.7-10.11 in GBC.
        \item Still, figure out how to generate multiple trajectories and which format to save in.
        \item Also, how to take the velocity data as input sequences with correct dimensions of input and layers.
        \item Is it necessary to build a multi-dimensional tensor and use embedding?
    \end{enumerate}

    \item[04.03.24] Read chapter 10.7-10.11 in GBC, the mathematical basis for RNNs is relevant in understanding how it is built using module in PyTorch. Read the paper from Xu et. al. \cite{xu:2022:conformal}, where they study conformal isometry in a model based on a continuous attractor neural network. They focused on a RNN that represented the self-position linearly and the input velocity additively, they also included ReLU. Noted down equations and thoughts in Goodnotes notebook, to get a better understanding of their implementation. In addition, I went through a couple of the papers refered to, and their github repos (Gao \cite{gao:2019:learning_gridlike, gao:2021:path_integration} and Banino \cite{banino:2018:vector_based}). 

    List of repos:
    \begin{description}
        \item[Gao]  \url{https://github.com/ruiqigao/GridCell}
        \item[Gao] \url{https://github.com/ruiqigao/grid-cell-path}
        \item[Xu] \url{https://github.com/DehongXu/grid-cell-rnn}
        \item[Sorscher] \url{https://github.com/ganguli-lab/grid-pattern-formation}
        \item[Banino] \url{https://github.com/google-deepmind/grid-cells}
        \item[RatInABox] \url{https://github.com/RatInABox-Lab/RatInABox}
    \end{description}
    
    To do:
    \begin{enumerate}
        \item Generate multiple trajectories using \verb|RatInABox|, and save in batches of trajectories. Look into the Sorscher implementation, as they use PyTorch (batch\_size, sequence\_length, input\_size). 
        \item The velocity data are input sequences, figure out correct dimensions of input and if it necessary to include encoder/decoder layers.
    \end{enumerate}

    \item[06.03.24] Meeting with Markus, to go over plan for thesis. Fixed the thesis document and put in the main section titles for the neuro background. Started with the computational background. Both sections which can be used in this project, maybe in lesser detail.

    To do: %
    \begin{enumerate}
        \item Fix code!
    \end{enumerate}

    \item[07.03.24] Wrote function for generating trajectories, and figured out how to put the position and velocity into a tensor and save to file.

    To do: %
    \begin{enumerate}
        \item Figure out dataloader in PyTorch.
        \item Start implementing RNN.
    \end{enumerate}

    \item[12.03.24] Wrote a draft introduction, including both an artificial and a biological perspective on neuroscience. Found relevant background on brain anatomy in the neuroscience textbook \cite{bear:2016:neuroscience}, in addition to some detailed theory in the book about learning and memory \cite{byrne:2008:learning_memory}. I have also set up a basic rnn using only a torch.rnn and a decoder. The code runs, however, it does not predict the correct path...! 

    To do: %
    \begin{enumerate}
        \item Build a model using the Module class provided by PyTorch.
        \item Test different parameters, optimizers etc.
        \item Customize the environment of the agent, maybe insert rewards etc.
    \end{enumerate}

    \item[14.03.24] Built VanillaRNN using the Module class. it runs, however, it does not initiate a hidden state before running. 

    To do: %
    \begin{enumerate}
        \item Fix initial hidden state.
        \item Test different parameters, optimizers etc.
        \item Customize the environment of the agent, maybe insert rewards etc.
    \end{enumerate}

    \item[15.03.24] Fixed the initiation of the hidden state, and the model now makes similar trajectory predictions. Need to shift the label (position) array one time step when computing loss and comparing paths.

    To do: %
    \begin{enumerate}
        \item Account for the difference in time, since the predicted position is one time step ahead of the label.
        \item Test different parameters, optimizers etc. to see if it is possible to decrease loss. 
        \item Customize the environment of the agent, could be interesting to insert objects and see it the agent can learn how to navigate the environment and recognize objects after retention.
    \end{enumerate}

    \item[18.03.24] Cleaned up the code and put it into scripts, fixed the time step difference when computing loss. Also added a plot showing the current model predictions for 5 trajectories. Fixed report setup, still needs proofreading and some more details in both the introduction and the progress report.

    To do: %
    \begin{enumerate}
        \item Finish report!
        \item Test different parameters, optimizers etc. to see if it is possible to decrease loss. 
        \item Customize the environment of the agent, could be interesting to insert objects and see it the agent can learn how to navigate the environment and recognize objects after retention.
    \end{enumerate}

    \item[08.04.24] Finish draft of introduction, and set up the structure of the theory section using keywords. Added a few articles on theory and method related subjects into reference section.

    To do: %
    \begin{enumerate}
        \item Fix training method, separate into forward and predict and include a separate method for training. 
        \item Set up new model where head direction is added as input, in addition to velocity. Compare both model accuracy.
        \item Experiment with different parameters, such as learning rate and schedulers.
        \item Write theory section, include biological and artificial background.
    \end{enumerate}

    \item[22.04.24] Finish the vanilla RNN and implemented a separate train method, write new main method to use new training scheme.

    To do: %
    \begin{enumerate}
        \item Set up new model where head direction is added as input, in addition to velocity. Compare both model accuracy.
        \item Experiment with different parameters, such as learning rate and schedulers.
        \item Start writing the report!
    \end{enumerate}

    \item[23.04.24] Adjusted some of the parameters to see if it affected the computation and prediction. When increasing number of hidden neurons the model seems more prone to gradient explosion, as the loss increase drastically. Also, tried to increase number of trajectories generated, and number of epochs.

    \begin{enumerate}
        \item Set up new model where head direction is added as input, in addition to velocity. Compare both model accuracy.
        \item Write up the theory section for both the biology and machine learning part. None of these sections need to be mathematically detailed, as this will be put in the methods section.
    \end{enumerate}

    \item[01.05.24] Started to write on the theory and method sections, but I'm struggling to put all the information I want to include in order. Should try to put it into a mind map to see if I can find the red thread or something.

    What I want is for the introduction to set the stage, I should mention some background here to ground the project in. I also have to present the layout of the report. 

    In the theory section I want to delve a bit deeper into what is presented in the introduction, such as previous experiments of rats performing spatial tasks and the importance of hippocampus in those tasks. For the machine learning part I want say something about the advantage of using computational tools in neuroscience, and some background for previous work using neural networks in the study of place cells etc.

    In the method section I will present any mathematical stuff related to the machine learning stuff, in addition to algorithms. I want to start out by presenting the basic feed forward neural networks, and move on to include recurrent neural networks for the time sequence data. If time allows I want to include something generative, the methods for this I'll include if necessary. I need to include a tool section and maybe a separate section for generating data, and mention what type of setup and data I produce and maybe why?

    The result section should be pretty straight forward, start with the default environment to build the model an make predictions. Tweek the model to see if I can lower the loss? Continue with comparing the model's performance on experimental data. If time allows, include objects and possibly generate trajectories based on learned location (learn short cut).

    Discuss and conclude the findings, suggest any future work.

    \item[21.05.24] Cleaned up the function for creating dataset and put it into a utils module, separated into subfunction to either import Sargolini data or generating synthetic trajectories. Main function control whether the data is saved or not. 

    Next up:
    \begin{enumerate}
        \item Write function to include other features when creating dataset, such as head-direction.
        \item Figure out the size and shape of the environment used in the Sargolini data.
        \item Figure out the argparser and dataclass.
    \end{enumerate}
\end{description}