{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict position based on velocity data\n",
    "\n",
    "1. Use RatInABox toolkit to generate data, figure out sequence length \n",
    "\n",
    "2. Build (vanilla) RNN model, using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ratinabox\n",
    "from ratinabox.Environment import Environment\n",
    "from ratinabox.Agent import Agent\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "path = \"../latex/figures/\"\n",
    "ratinabox.stylize_plots()\n",
    "ratinabox.autosave_plots = False\n",
    "ratinabox.figure_directory = path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(2024)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up default experiment \n",
    "env = Environment()\n",
    "ag = Agent(env)\n",
    "\n",
    "for i in range(int(60 / ag.dt)):\n",
    "    ag.update()\n",
    "\n",
    "X = torch.tensor(ag.history[\"vel\"])\n",
    "y = torch.tensor(ag.history[\"pos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Dataloader to set up? Or put into arrays as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 2\n",
    "n_steps = 20\n",
    "n_hidden = 10\n",
    "n_layers = 1\n",
    "n_output = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build vanilla RNN, how to handle the output (number of neurons)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output) -> None:\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        # Where to place which layer and use rnn layer instead of fully connected?\n",
    "        self.n_hidden = n_hidden \n",
    "        self.input_hidden = nn.Linear(n_input + n_hidden, n_hidden)\n",
    "        self.input_output = nn.Linear(n_input + n_hidden, n_output)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def feed_forward(self, x_tensor, h_tensor):\n",
    "        # This does not work! Getting wrong dimension\n",
    "        cat = torch.cat((x_tensor, h_tensor), dim=2)\n",
    "        hidden = self.input_hidden(cat)\n",
    "        out = self.input_output(cat)\n",
    "        out = self.softmax(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Is it necessary to initialize recurrent weights here?\n",
    "        return torch.zeros(2, self.n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with short seq\n",
    "x_tensor = torch.transpose_copy(X_train[0:10,:], 0, 1)\n",
    "y_tensor = torch.transpose_copy(y_train[0:10,:], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VanillaRNN(n_input, n_hidden, n_output)\n",
    "h_tensor = model.init_hidden()\n",
    "\n",
    "h_tensor.shape\n",
    "# out, h = model.feed_forward(x_tensor, h_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0098, -0.0704],\n",
       "        [ 0.0139, -0.0801],\n",
       "        [ 0.0142, -0.0780],\n",
       "        ...,\n",
       "        [ 0.1053,  0.0205],\n",
       "        [ 0.1108, -0.0293],\n",
       "        [ 0.0839, -0.0264]], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fys_stk4155",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
